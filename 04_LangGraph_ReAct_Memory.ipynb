{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import uuid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tool 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 사용자 정의 - @tool decorator`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"qwen2.5:1.5b\") \n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"./db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_menu(query: str) -> List[str]:\n",
    "    \"\"\"레스토랑 메뉴에서 정보를 검색합니다.\"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=6)\n",
    "\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 메뉴 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LangChain 내장 도구`\n",
    "- 일반 웹 검색을 위한 Tavily 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"데이터베이스에 존재하지 않는 정보 또는 최신 정보를 인터넷에서 검색합니다.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=3)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. bind_tools() 함수로 LLM과 Tool 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 도구 목록\n",
    "tools = [search_menu, search_web]\n",
    "\n",
    "# 모델에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 도구 호출 ( Vector DB )\n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"스테이크 메뉴의 가격은 얼마인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 ( Tavily )\n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"LangGraph는 무엇인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"3+3은 얼마인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 도구 노드(ToolNode) \n",
    "- AI 모델이 요청한 도구(tool) 호출을 실행하는 역할을 처리하는 LangGraph 콤포넌트\n",
    "- 작동 방식:\n",
    "    - 가장 최근의 AIMessage에서 도구 호출 요청을 추출 (반드시, AIMessage는 반드시 tool_calls가 채워져 있어야 함)\n",
    "    - 요청된 도구들을 병렬로 실행\n",
    "    - 각 도구 호출에 대해 ToolMessage를 생성하여 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 도구 노드(Tool Node) 정의`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 도구 노드 정의 \n",
    "tools = [search_menu, search_web]\n",
    "tool_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"스테이크 메뉴의 가격은 얼마인가요?\")])\n",
    "\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 도구 노드(Tool Node) 실행`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 결과를 메시지로 추가하여 실행 \n",
    "results = tool_node.invoke({\"messages\": [tool_call]})\n",
    "\n",
    "# 실행 결과 출력하여 확인 \n",
    "for result in results['messages']:\n",
    "    print(result.content)\n",
    "    print('**** --------------------------- ****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델을 이용하여 도구를 호출하여 실행 \n",
    "results = tool_node.invoke({\"messages\": [llm_with_tools.invoke(\"LangGraph는 무엇인가요?\")]})\n",
    "\n",
    "# 실행 결과 출력하여 확인 \n",
    "for result in results['messages']:\n",
    "    print(result.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ReAct Agent\n",
    "- ReAct(Reasoning and Acting) : 가장 일반적인 에이전트\n",
    "- 동작 방식:\n",
    "    - 행동 (act): 모델이 특정 도구를 호출\n",
    "    - 관찰 (observe): 도구의 출력을 모델에 다시 전달\n",
    "    - 추론 (reason): 모델이 도구 출력을 바탕으로 다음 행동을 결정 (예: 또 다른 도구를 호출하거나 직접 응답을 생성)\n",
    "\n",
    "- 논문: https://arxiv.org/abs/2210.03629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 랭그래프 내장 ReAct 에이전트 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "graph = create_react_agent(\n",
    "    llm, \n",
    "    tools=tools, \n",
    ")\n",
    "\n",
    "print(type(graph))\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"messages\": [HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# 시스템 프롬프트\n",
    "system_prompt = dedent(\"\"\"\n",
    "You are an AI assistant designed to answer human questions. \n",
    "You can use the provided tools to help generate your responses.\n",
    "\n",
    "Follow these steps to answer questions:\n",
    "    1. Carefully read and understand the question.\n",
    "    2. Use the provided tools to obtain necessary information.\n",
    "    3. Immediately after using a tool, cite the source using the format below.\n",
    "    4. Construct an accurate and helpful answer using the tool outputs and citations.\n",
    "    5. Provide the final answer when you determine it's complete.\n",
    "\n",
    "When using tools, follow this format:\n",
    "    Action: tool_name\n",
    "    Action Input: input for the tool\n",
    "\n",
    "Immediately after receiving tool output, cite the source as follows:\n",
    "    [Source: tool_name | document_title/item_name | url/file_path]\n",
    "\n",
    "For example:\n",
    "    Action: search_menu\n",
    "    Action Input: 스테이크\n",
    "    \n",
    "    (After receiving tool output)\n",
    "    [Source: search_menu | 스테이크 | ./data/data.txt]\n",
    "    스테이크에 대한 정보는 다음과 같습니다...\n",
    "\n",
    "    Action: search_web\n",
    "    Action Input: History of AI\n",
    "\n",
    "    (After receiving tool output)\n",
    "    [Source: search_web | AI History | https://en.wikipedia.org/wiki/History_of_artificial_intelligence]\n",
    "    AI의 역사는 다음과 같이 요약됩니다...\n",
    "\n",
    "If tool use is not necessary, answer directly.\n",
    "\n",
    "Your final answer should be clear, concise, and directly related to the user's question. \n",
    "Ensure that every piece of factual information in your response is accompanied by a citation.\n",
    "\n",
    "Remember: ALWAYS include these citations for all factual information, tool outputs, and referenced documents in your response. \n",
    "Do not provide any information without a corresponding citation.\n",
    "\"\"\")\n",
    "\n",
    "# 그래프 생성 \n",
    "graph = create_react_agent(\n",
    "    llm, \n",
    "    tools=tools, \n",
    "    #state_modifier=system_prompt,\n",
    "    #system_message=SystemMessage(content=system_prompt),\n",
    "    )\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")\n",
    "    ]\n",
    "#inputs = {\"messages\": [HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")]}\n",
    "#messages = graph.invoke(inputs)\n",
    "\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 조건부 엣지 함수를 사용자 정의`\n",
    "- `should_continue` 함수에서 도구 호출 여부에 따라 종료 여부를 결정\n",
    "- 도구 실행이 필요한 경우에는 그래프가 종료되지 않고 계속 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# LangGraph MessagesState 사용\n",
    "class GraphState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# 노드 구성 \n",
    "def call_model(state: GraphState):\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    messages = [system_message] + state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # 도구 호출이 있으면 도구 실행 노드로 이동\n",
    "    if last_message.tool_calls:\n",
    "        return \"execute_tools\"\n",
    "    # 도구 호출이 없으면 답변 생성하고 종료 \n",
    "    return END\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"execute_tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"execute_tools\": \"execute_tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"execute_tools\", \"call_model\")\n",
    "\n",
    "graph = builder.compile()\n",
    "print(type(graph))\n",
    "\n",
    "# 그래프 출력 \n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"messages\": [HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) tools_condition 활용`\n",
    "- LangGraph에서 제공하는 도구 사용을 위한 조건부 엣지 함수\n",
    "- 최신 메시지(결과)가 도구 호출이면 -> `tools_condition`이 도구로 라우팅\n",
    "- 최신 메시지(결과)가 도구 호출이 아니면 -> `tools_condition`이 `END`로 라우팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# 노드 함수 정의\n",
    "def call_model(state: GraphState):\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    messages = [system_message] + state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"agent\", call_model)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"agent\")\n",
    "\n",
    "# tools_condition을 사용한 조건부 엣지 추가\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"messages\": [HumanMessage(content=\"파스타에 어울리는 음료는 무엇인가요?\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MemorySaver\n",
    "\n",
    "1. 상태의 일시성 문제:\n",
    "   - 기본적으로 그래프 실행 시 상태는 일시적 (stateless)\n",
    "   - 그래프를 재실행하는 경우 상태가 초기화되는 문제가 있음 \n",
    "   - 따라서, 중단이 있는 다중 턴 대화가 어려움 \n",
    "\n",
    "2. MemorySaver 기능:\n",
    "   - 가장 쉽게 사용할 수 있는 체크포인터 (각 단계 후 그래프 상태를 자동으로 저장)\n",
    "   - 그래프 상태를 위한 인메모리 키-값 저장소\n",
    "   - 지속성(persistence) 있는 메모리 기능을 제공하여 그래프 객체가 체크포인터부터 이어서 실행 가능 \n",
    "\n",
    "3. 메모리의 필요성:\n",
    "   - 대화의 연속성: 여러 턴에 걸친 대화를 유지 \n",
    "   - 중단 허용: 대화 중 중단이 있어도 이전 상태를 복원\n",
    "   - 유연한 상태 관리: 다양한 대화 스레드를 독립적으로 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. 사용자 정의 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행 - 이전 대화 내용을 기억하는지 못하는 문제가 있음 \n",
    "inputs = {\"messages\": [HumanMessage(content=\"이 중에 하나만 추천해주세요.\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 체크포인터 지정`\n",
    "- 그래프를 컴파일할 때 체크포인터를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 메모리 초기화 \n",
    "memory = MemorySaver()\n",
    "\n",
    "# 체크포인터 지정하여 그래프 컴파일 \n",
    "graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 체크포인터 사용`\n",
    "- 메모리 사용 시 `thread_id`를 지정 \n",
    "- 체크포인터는 그래프의 각 단계에서 상태를 기록 (그래프 각 단계의 모든 상태를 컬렉션으로 저장)\n",
    "- 나중에 `thread_id`를 사용하여 이 스레드에 접근 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "messages = [HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")]\n",
    "messages = graph_memory.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "messages = [HumanMessage(content=\"둘 중에 더 저렴한 메뉴는 무엇인가요?\")]\n",
    "messages = graph_memory.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 내장 ReAct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# 메모리 초기화 \n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 생성 \n",
    "graph = create_react_agent(\n",
    "    llm, \n",
    "    tools=tools, \n",
    "    #state_modifier=system_prompt,\n",
    "    checkpointer=memory,\n",
    "    )\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "#messages = [HumanMessage(content=\"채식주의자를 위한 메뉴가 있나요?\")]\n",
    "messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=\"채식주의자를 위한 메뉴가 있나요?\")\n",
    "    ]\n",
    "\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "messages = [HumanMessage(content=\"방금 답변에 대한 출처가 있나요?\")]\n",
    "messages = graph.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 메모리 사용 준비\n",
    "memory = MemorySaver()\n",
    "graph_memory = builder.compile(checkpointer=memory)\n",
    "\n",
    "# 예시 질문들\n",
    "example_questions = [\n",
    "    \"채식주의자를 위한 메뉴를 추천해주세요.\",\n",
    "    \"오늘의 스페셜 메뉴는 무엇인가요?\",\n",
    "    \"파스타에 어울리는 음료는 무엇인가요?\"\n",
    "]\n",
    "\n",
    "# 답변 메시지 처리를 위한 함수\n",
    "def process_message(message: str, history: List[Tuple[str, str]], thread_id: str) -> str:\n",
    "    try:\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        inputs = {\"messages\": [HumanMessage(content=message)]}\n",
    "        \n",
    "        result = graph_memory.invoke(inputs, config=config)\n",
    "        \n",
    "        if \"messages\" in result:\n",
    "            # 메시지 로깅 (선택사항)\n",
    "            print(f\"스레드 ID: {thread_id}\")\n",
    "            for msg in result[\"messages\"]:\n",
    "                msg.pretty_print()\n",
    "\n",
    "            last_message = result[\"messages\"][-1]\n",
    "            if isinstance(last_message, AIMessage):\n",
    "                return last_message.content\n",
    "\n",
    "        return \"응답을 생성하지 못했습니다.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "\n",
    "# 챗봇 클래스 생성\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        self.thread_id = str(uuid.uuid4())\n",
    "\n",
    "    def chat(self, message: str, history: List[Tuple[str, str]]) -> str:\n",
    "        print(f\"Thread ID: {self.thread_id}\")\n",
    "        response = process_message(message, history, self.thread_id)\n",
    "        return response\n",
    "\n",
    "chatbot = ChatBot()\n",
    "\n",
    "\n",
    "# ChatInterface 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot.chat,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다. 정보의 출처를 함께 제공합니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Gradio 앱 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
