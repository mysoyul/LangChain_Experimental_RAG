{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47541,
     "status": "ok",
     "timestamp": 1739077755224,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "o1JUEqxz8ZNx",
    "outputId": "dc3786e2-f375-466b-c8a5-9abbd0b0254e"
   },
   "outputs": [],
   "source": [
    "%pip install -q gradio\n",
    "%pip install -q openai\n",
    "%pip install -q langchain\n",
    "%pip install -q -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9njs8WTG7Ju"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "messages = [HumanMessage(content=\"파이썬 이란?\")]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def chat_respond(message, chat_history):  \n",
    "    human_message = HumanMessage(content=message)\n",
    "    response = llm.invoke([human_message])\n",
    "    bot_message = response.content\n",
    "    \n",
    "    chat_history.append({\"role\": \"user\", \"content\": human_message.content})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chat_history  \n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:  \n",
    "    chatbot = gr.Chatbot(label=\"채팅창\", type=\"messages\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(chat_respond, [msg, chatbot], [msg, chatbot])  \n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  \n",
    "\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMWopfhh7Q+wJPj0YUKzfcG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
