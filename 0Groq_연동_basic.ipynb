{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000240519D5790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000240521220F0>, root_client=<openai.OpenAI object at 0x000002404EEF1610>, root_async_client=<openai.AsyncOpenAI object at 0x0000024051C77FE0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 파이썬은 1980년대 후반에 네덜란드계 프로그래머 귀도 반 로섬(Guido van Rossum)에 의해 개발된 고급 프로그래밍 언어입니다. 파이썬은 코드의 가독성과 간결함, 쉬운 문법 등으로 유명하며, 다양한 분야에서 널리 사용됩니다.\n",
      "\n",
      "**파이썬의 특징**\n",
      "\n",
      "1. **쉬운 문법**: 파이썬은 간단하고 직관적인 문법을 가지고 있어, 프로그래밍을 처음 시작하는 사람들도 쉽게 배울 수 있습니다.\n",
      "2. **가독성**: 파이썬 코드는 들여쓰기(indentation)를 통해 블록을 구분하고, 명확한 변수 이름과 함수 이름을 사용하므로 가독성이 뛰어납니다.\n",
      "3. **대체로 느림**: 파이썬은 인터프리터 언어이기 때문에, 코드가 실행될 때마다 해석과 실행이 이루어져 속도가 느릴 수 있습니다. 하지만, JIT(Just-In-Time) 컴파일러와 같은 기술을 사용하여 성능을 개선할 수 있습니다.\n",
      "4. **객체 지향**: 파이썬은 객체 지향 프로그래밍(OOP)을 지원하며, 클래스, 객체, 상속, 다형성 등의 개념을 사용할 수 있습니다.\n",
      "5. **대규모 라이브러리**: 파이썬은 방대한 라이브러리와 모듈을 보유하고 있어, 다양한 작업에 활용할 수 있습니다. 예를 들어, 데이터 분석을 위한 Pandas, 웹 개발을 위한 Django, 컴퓨터 비전을 위한 OpenCV 등이 있습니다.\n",
      "\n",
      "**파이썬의 활용 분야**\n",
      "\n",
      "1. **데이터 분석 및 과학**: 파이썬은 데이터 분석, 머신러닝, 데이터 시각화 등에 널리 사용됩니다. Pandas, NumPy, Matplotlib, Scikit-learn 등의 라이브러리가 유명합니다.\n",
      "2. **웹 개발**: 파이썬은 웹 개발을 위해 Django, Flask 등의 프레임워크를 제공합니다.\n",
      "3. **스크립팅**: 파이썬은 간단한 스크립트를 작성하여 자동화 작업을 수행하는 데 적합합니다.\n",
      "4. **게임 개발**: 파이썬은 Pygame 라이브러리를 통해 게임 개발에도 사용됩니다.\n",
      "5. **교육**: 파이썬은 프로그래밍을 처음 배우는 학생들에게 인기 있는 언어입니다.\n",
      "\n",
      "**파이썬의 버전**\n",
      "\n",
      "파이썬은 크게 두 가지 버전으로 나뉩니다.\n",
      "\n",
      "* **파이썬 2.x**: 2000년에 출시된 파이썬 2.x 버전은 2015년에 지원이 종료되었습니다.\n",
      "* **파이썬 3.x**: 2008년에 출시된 파이썬 3.x 버전은 현재 가장 널리 사용되는 버전입니다.\n",
      "\n",
      "파이썬은 다양한 분야에서 널리 사용되는 언어이며, 쉽고 직관적인 문법과 방대한 라이브러리로 인해 개발자들에게 사랑받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"지구의 자전주기는 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지구의 자전주기는 24시간입니다. 좀 더 정확하게 말하면, 지구는 자전축을 중심으로 서쪽에서 동쪽으로 하루에 360도, 즉 24시간마다 한 바퀴를 돕니다. 자전주기는 태양이 같은 위치에 다시 나타나는 시간으로 정의되는 '태양일'과, 별이 같은 위치에 다시 나타나는 시간으로 정의되는 '항성일'로 구분할 수 있습니다. 태양일은 24시간, 항성일은 23시간 56분 4초입니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
