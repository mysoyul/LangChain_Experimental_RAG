{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1cf819",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cb932",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b09cb",
   "metadata": {},
   "source": [
    "`(2) 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54412ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## 2. 도구 호출 (Tool Calling)\n",
    "- 도구 호출은 LLM이 특정 작업을 수행하기 위해 외부 기능을 호출하는 기능\n",
    "- 이를 통해 LLM은 외부 API 통합 등 더 복잡한 작업을 수행할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdccc6b",
   "metadata": {},
   "source": [
    "### 2-1. 랭체인 내장 도구\n",
    "- Tavily 웹 검색 도구 (예시)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e257",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in search_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(web_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b600d9",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# 웹 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요 없는 LLM 호출을 수행\n",
    "query = \"안녕하세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8df009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# AIMessage의 속성 확인\n",
    "pprint(vars(ai_msg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pprint(ai_msg)\n",
    "print(\"#\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "\n",
    "print(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86835305",
   "metadata": {},
   "source": [
    "`(3) 도구(tool) 실행하기`\n",
    "\n",
    "#### 방법 1: 직접 도구 호출 처리한 결과로 ToolMessage 객체 생성\n",
    "\n",
    "* 이 방법은 AI 메시지에서 첫 번째 도구 호출을 가져와 직접 처리한다.\n",
    "* 'args'를 사용하여 도구를 호출하고 결과를 얻는다.\n",
    "* 도구 호출 결과를 사용하여 ToolMessage 객체를 생성한다.\n",
    "* 도구 호출의 ID와 이름을 포함하여 더 구조화된 ToolMessage 메시지를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']} 호출 결과:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75bf7f",
   "metadata": {},
   "source": [
    "#### 방법 2: 도구 직접 호출하여 바로 ToolMessage 객체 생성\n",
    "\n",
    "* 이 방법은 도구를 직접 호출하여 ToolMessage 객체를 생성한다.\n",
    "* 가장 간단하고 직관적인 방법으로, LangChain의 추상화를 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_call  {'name': 'tavily_search_results_json', 'args': {'query': 'wine pairing with steak'}, 'id': 'call_LrHyxTadqHDjW7J6LOWEaoSi', 'type': 'tool_call'}\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "print(type(tool_message))\n",
    "\n",
    "# 특정 속성들만 확인\n",
    "print(\"\\n=== 주요 속성들 ===\")\n",
    "attributes = ['content', 'tool_call_id', 'name', 'type', 'additional_kwargs']\n",
    "for attr in attributes:\n",
    "    if hasattr(tool_message, attr):\n",
    "        print(f\"{attr}: {getattr(tool_message, attr)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.tool_call_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01309400",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tool_message.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e71c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "\n",
    "# tool_messages = web_search.batch([tool_call])\n",
    "\n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20257ba",
   "metadata": {},
   "source": [
    "`(4) ToolMessage를 LLM에 전달하여 답변을 생성하기`\n",
    "\n",
    "* 파라미터 이름이 config여야 하는 이유: @chain 데코레이터가 config라는 이름만 특별히 인식하도록 설계되었습니다.\n",
    "* config 생략 가능한 이유: @chain이 자동으로 기본 RunnableConfig()를 생성해서 전달하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5de654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "tavily_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_tool])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    tool_msgs = tavily_tool.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = web_search_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f49a9f",
   "metadata": {},
   "source": [
    "### 2-2. 사용자 정의 도구\n",
    "- @tool decorator를 통해 사용자 정의 도구를 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c058ff5",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d5144",
   "metadata": {},
   "source": [
    "### 2-3. Runnable 객체를 도구(tool) 변환\n",
    "- 문자열이나 dict 입력을 받는 Runnable을 도구로 변환\n",
    "- as_tool 메서드를 사용\n",
    "\n",
    "- wikipedia 설치\n",
    "```\n",
    "    poetry add wikipedia\n",
    "```\n",
    "- [WikipediaLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.wikipedia.WikipediaLoader.html) 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수 \n",
    "def search_wiki(input_data: dict) -> List[Document]:\n",
    "    \"\"\"Search Wikipedia documents based on user input (query) and return k documents\"\"\"\n",
    "    query = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)  \n",
    "    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return (default is 2)\")\n",
    "\n",
    "# RunnableLambda 함수를 사용하여 위키피디아 문서 로더를 Runnable로 변환 \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name=\"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a specified number of documents. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위키 검색 실행\n",
    "query = \"파스타의 유래\"\n",
    "wiki_results = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in wiki_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b812a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_search_func, wiki_search])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06d2ed",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인`\n",
    "- 위키피디아 문서를 검색하고 내용을 요약하는 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "# LLM 및 요약 체인 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "# 요약 테스트 \n",
    "summarized_text = summary_chain.invoke({\"query\":\"파스타의 유래\"})\n",
    "pprint(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "# as_tool 메소드를 사용하여 도구 객체로 변환\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78824759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_search_func, wiki_summary])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.tool_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 실행 \n",
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[wiki_summary])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = wiki_summary_chain.invoke(\"파스타의 유래에 대해서 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f828547",
   "metadata": {},
   "source": [
    "### 2-4. 벡터저장소 검색기\n",
    "- @tool decorator 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9dc12",
   "metadata": {},
   "source": [
    "`(1) 문서 로드 및 인덱싱`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 분할 (Chunking)\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    메뉴 항목을 분리하는 함수 \n",
    "    \"\"\"\n",
    "    # 정규표현식 정의 \n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09f288",
   "metadata": {},
   "source": [
    "### Embedding을 하기 위해 Ollama Qwen2.5 설치\n",
    "```\n",
    "ollama run qwen2.5:1.5b\n",
    "\n",
    "ollama ls\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"qwen2.5:1.5b\") \n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "menu_db = FAISS.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "# FAISS 인덱스 저장 (선택사항)\n",
    "menu_db.save_local(\"./db/menu_db\")\n",
    "\n",
    "\n",
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 쿼리 테스트\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf58d36",
   "metadata": {},
   "source": [
    "- 와인 메뉴에 대해서도 같은 작업을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc82b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 메뉴 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "\n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "wine_db = FAISS.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "# 병합된 DB 다시 저장\n",
    "wine_db.save_local(\"./db/wine_db\")\n",
    "\n",
    "wine_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "docs = wine_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040915b",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"./db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def db_search_menu_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(db_search_menu_func))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(db_search_menu_func.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(db_search_menu_func.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(db_search_menu_func.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# wine db 벡터 저장소 로드\n",
    "wine_db = FAISS.load_local(\n",
    "    \"./db/wine_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def db_search_wine_func(query: str) -> List[Document]:\n",
    "   \"\"\"\n",
    "   Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "   Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "   \"\"\"\n",
    "   docs = wine_db.similarity_search(query, k=2)\n",
    "   if len(docs) > 0:\n",
    "      return docs\n",
    "   \n",
    "   return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(db_search_wine_func))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(db_search_wine_func.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(db_search_wine_func.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(db_search_wine_func.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[db_search_menu_func, db_search_wine_func])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 와인도 추천 해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b74a1",
   "metadata": {},
   "source": [
    "`(3) 여러 개의 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "for tool in tools:\n",
    "    print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_menu_func\":\n",
    "            tool_message = db_search_menu_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_wine_func\":\n",
    "            tool_message = db_search_wine_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"시그니처 스테이크의 가격과 특징은 무엇인가요? 와인도 해주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"파스타 메뉴가 있나요? 파스타의 역사 또는 유래를 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b78e3",
   "metadata": {},
   "source": [
    "## 3. Few-shot 프롬프팅 \n",
    "- 각 도구의 용도를 구분하여 few-shot 예제로 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e6b9",
   "metadata": {},
   "source": [
    "### 3-1. Few-shot 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd743c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_menu_func\", \"args\": {\"query\": \"트러플 리조또\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리\", tool_call_id=\"1\"),    \n",
    "    AIMessage(\"트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"트러플 리조또\", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. \\\n",
    "                주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_wine_func\", \"args\": {\"query\": \"트러플 리조또에 어울리는 와인\"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. \\\n",
    "                2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.\", tool_call_id=\"3\"),\n",
    "    AIMessage(\"트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다.\\\n",
    "               주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, \\\n",
    "              주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. \\\n",
    "              특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오,\\\n",
    "               그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인도 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f10c84",
   "metadata": {},
   "source": [
    "### 3-2. 답변 생성 체인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        # [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_wine_func\":\n",
    "            tool_message = db_search_wine_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_menu_func\":\n",
    "            tool_message = db_search_menu_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해 주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11927ed4",
   "metadata": {},
   "source": [
    "## 4. LangChain Agent 사용\n",
    "- 유의사항: 프롬프트에 \"agent_scratchpad\",  \"input\" 변수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dad12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calling Agent 생성\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor 생성 \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd37cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentExecutor 실행\n",
    "\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb411fca",
   "metadata": {},
   "source": [
    "## 5. Gradio 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-2:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# 데모 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd26485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb837bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
