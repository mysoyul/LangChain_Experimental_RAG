{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4083c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e720b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_separator(title=\"\"):\n",
    "    \"\"\"구분선 출력\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if title:\n",
    "        print(f\" {title}\")\n",
    "        print(\"=\"*80)\n",
    "    print()\n",
    "\n",
    "def print_parameters(params, title):\n",
    "    \"\"\"파라미터 출력\"\"\"\n",
    "    print(f\" {title} 파라미터:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\" {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# 모델 파라미터 설정 (Before / After)\n",
    "before_params = {\n",
    "    \"temperature\": 0.7,         # 높은 창의성 (다양한 답변)\n",
    "    \"max_tokens\": 300,          # 짧은 응답 길이\n",
    "    \"frequency_penalty\": 0.5,   # 높은 반복 억제\n",
    "    \"presence_penalty\": 0.5,    # 높은 새로운 단어 장려\n",
    "}\n",
    "\n",
    "after_params = {\n",
    "    \"temperature\": 0.3,         # 낮은 창의성 (정확한 답변)\n",
    "    \"max_tokens\": 800,          # 긴 응답 길이\n",
    "    \"top_p\": 0.85,              # 확률 기반 샘플링 추가\n",
    "    \"frequency_penalty\": 0.2,   # 낮은 반복 억제 (자연스러운 답변)\n",
    "    \"presence_penalty\": 0.3,    # 낮은 새로운 단어 장려\n",
    "}\n",
    "\n",
    "# 파라미터 정보 출력\n",
    "print_separator(\"모델 파라미터 비교\")\n",
    "print_parameters(before_params, \"BEFORE\")\n",
    "print_parameters(after_params, \"AFTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca60847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 모델 생성 (Before / After)\n",
    "print(\" 모델 초기화 중...\")\n",
    "\n",
    "try:\n",
    "    # Before 모델 (기본적인 설정)\n",
    "    before_model = ChatOpenAI(\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "        **before_params\n",
    "    )\n",
    "    \n",
    "    # After 모델 (최적화된 설정) - 변수명 오타 수정\n",
    "    after_model = ChatOpenAI(\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "        **after_params\n",
    "    )\n",
    "    \n",
    "    print(\" 모델 초기화 완료\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" 모델 초기화 실패: {e}\")\n",
    "    print(\"API 키를 확인하세요.\")\n",
    "    exit(1)\n",
    "\n",
    "# 프롬프트 구성\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 여행 전문가입니다. 사용자의 요청에 맞는 최적의 여행지를 추천해 주세요.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "# 체인 생성\n",
    "before_chain = chat_prompt | before_model\n",
    "after_chain = chat_prompt | after_model\n",
    "\n",
    "# 동일한 질문으로 비교 (파라미터 차이 효과 확인)\n",
    "test_question = \"가족과 함께 3박 4일 동안 한국에서 여유롭게 여행할 수 있는 일정을 동선을 고려하여 자세하게 추천해 주세요.\"\n",
    "\n",
    "print(\" 동일한 질문으로 파라미터 차이 비교:\")\n",
    "print(f\"질문: {test_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_with_timing(chain, question, model_name):\n",
    "    \"\"\"시간 측정과 함께 모델 실행\"\"\"\n",
    "    print(f\"\\n {model_name} 모델 실행 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\"user_input\": question})\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        print(f\" 실행 시간: {execution_time:.2f}초\")\n",
    "        print(f\" 응답 길이: {len(response.content)}자\")\n",
    "        \n",
    "        return response, execution_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 실행 실패: {e}\")\n",
    "        return None, 0\n",
    "\n",
    "# Before 모델 실행\n",
    "print_separator(\"BEFORE 모델 결과\")\n",
    "before_response, before_time = execute_with_timing(before_chain, test_question, \"BEFORE\")\n",
    "\n",
    "if before_response:\n",
    "    print(\"\\n 응답 내용:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(before_response.content)\n",
    "\n",
    "# After 모델 실행  \n",
    "print_separator(\"AFTER 모델 결과\")\n",
    "after_response, after_time = execute_with_timing(after_chain, test_question, \"AFTER\")\n",
    "\n",
    "if after_response:\n",
    "    print(\"\\n 응답 내용:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(after_response.content)\n",
    "\n",
    "# 비교 분석\n",
    "print_separator(\"성능 비교 분석\")\n",
    "\n",
    "if before_response and after_response:\n",
    "    print(\" 성능 지표 비교:\")\n",
    "    print(f\"   실행 시간: BEFORE {before_time:.2f}초 vs AFTER {after_time:.2f}초\")\n",
    "    print(f\"   응답 길이: BEFORE {len(before_response.content)}자 vs AFTER {len(after_response.content)}자\")\n",
    "    \n",
    "    # 응답 길이 차이 분석\n",
    "    length_diff = len(after_response.content) - len(before_response.content)\n",
    "    if length_diff > 0:\n",
    "        print(f\"    AFTER가 {length_diff}자 더 길어짐 (더 상세한 정보)\")\n",
    "    elif length_diff < 0:\n",
    "        print(f\"    AFTER가 {abs(length_diff)}자 더 짧아짐 (더 간결한 정보)\")\n",
    "    else:\n",
    "        print(f\"    두 응답의 길이가 동일함\")\n",
    "    \n",
    "    # 시간 차이 분석\n",
    "    time_diff = after_time - before_time\n",
    "    if time_diff > 0:\n",
    "        print(f\"    AFTER가 {time_diff:.2f}초 더 소요됨\")\n",
    "    elif time_diff < 0:\n",
    "        print(f\"    AFTER가 {abs(time_diff):.2f}초 더 빨름\")\n",
    "    else:\n",
    "        print(f\"    실행 시간이 거의 동일함\")\n",
    "\n",
    "# 추가 분석: 다양한 질문으로 테스트\n",
    "print_separator(\"추가 테스트: 다양한 질문\")\n",
    "\n",
    "additional_questions = [\n",
    "    \"부산 1일 여행 코스를 추천해 주세요.\",\n",
    "    \"제주도에서 가족이 즐길 수 있는 액티비티는?\",\n",
    "    \"서울에서 한옥마을 체험할 수 있는 곳은?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(additional_questions, 1):\n",
    "    print(f\"\\n테스트 {i}: {question}\")\n",
    "    \n",
    "    # Before 모델\n",
    "    before_resp, before_t = execute_with_timing(before_chain, question, f\"BEFORE-{i}\")\n",
    "    \n",
    "    # After 모델  \n",
    "    after_resp, after_t = execute_with_timing(after_chain, question, f\"AFTER-{i}\")\n",
    "    \n",
    "    if before_resp and after_resp:\n",
    "        print(f\"    길이 차이: {len(after_resp.content) - len(before_resp.content)}자\")\n",
    "        print(f\"    시간 차이: {after_t - before_t:.2f}초\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
