{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Reducer\n",
    "- Reducer는 LangGraph에서 상태 업데이트를 관리하는 중요한 개념\n",
    "- 그래프의 각 노드의 출력을 그래프의 상태에 통합하는 방법을 정의\n",
    "- Reducer의 필요성\n",
    "    - 상태 덮어쓰기 문제: 기본적으로 각 노드의 반환값은 해당 상태 키의 이전 값을 덮어쓰는 방식으로 동작 (override)\n",
    "    - 누적 업데이트 필요: 특히 메시지 리스트와 같은 경우, 이전 상태에 새로운 값을 추가하고 싶을 때가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Reducer를 별도로 지정하지 않은 경우 `\n",
    "- reducer를 별도로 지정하지 않은 경우 기존 값을 덮어쓰는 방식으로 동작\n",
    "- 기본 reducer는 상태에 대해 별도의 설정 없이 사용될 때 자동으로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 상태 정의 \n",
    "class DocumentState(TypedDict):\n",
    "    query: str\n",
    "    documents: List[str]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(DocumentState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Reducer를 별도로 지정하는 경우 `\n",
    "- `Annotated` 사용하여 지정한 reducer 작동 방식에 따라 기존 상태 정보를 업데이트 \n",
    "- 리스트를 병합하는 `operator.add`를 사용하면, activity_log를 누적하는 방식으로 노드를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "class ReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], add]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\"}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Custom Reducer 사용 `\n",
    "- 상태 업데이트가 기본적인 덮어쓰기나 병합만으로 해결되지 않을 때 유용한 방법\n",
    "- 중복 제거, 최대/최소 값 유지, 조건부 병합 등의 특정 비즈니스 로직이 필요한 경우에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "\n",
    "# Custom reducer: 중복된 문서를 제거하며 리스트 병합\n",
    "def reduce_unique_documents(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Combine two lists of documents, removing duplicates.\"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    # 중복 제거: set을 사용하여 중복된 문서를 제거하고 다시 list로 변환\n",
    "    return list(set(left + right))\n",
    "\n",
    "# 상태 정의 (documents 필드 포함)\n",
    "class CustomReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], reduce_unique_documents]  # Custom Reducer 적용\n",
    "\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(CustomReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\", \"documents\": []}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\", final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MessageGraph\n",
    "- LangChain의 ChatModel은 Message 객체 목록을 입력으로 처리 (StateGraph의 특수한 유형)\n",
    "- 이러한 메시지들은 HumanMessage(사용자 입력)나 AIMessage(LLM 응답) 등 다양한 형태로 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Messages State 정의`\n",
    "- 이전 대화 기록을 그래프 상태에 메시지 목록으로 저장하는 것이 유용\n",
    "- 그래프 상태에 Message 객체 목록을 저장하는 키(채널)를 추가하고, 이 키에 리듀서 함수를 추가 \n",
    "- 리듀서 함수 선택:\n",
    "    - operator.add를 사용하면: 새 메시지를 기존 목록에 단순히 추가\n",
    "    - add_messages 함수를 사용하면:\n",
    "        - 새 메시지는 기존 목록에 추가\n",
    "        - 기존 메시지 업데이트도 올바르게 처리 (메시지 ID를 추적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 기본 State 초기화 방법을 사용\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph MessagesState라는 미리 만들어진 상태를 사용\n",
    "from langgraph.graph import MessagesState\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    # messages 키는 기본 제공 - 다른 키를 추가하고 싶을 경우 아래 주석과 같이 적용 가능 \n",
    "    documents: List[Document]\n",
    "    grade: float\n",
    "    num_generation: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) RAG Chain 구성`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)\n",
    "- LangChain Runnable로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"qwen2.5:1.5b\") \n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"./db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# LLM 모델 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# RAG 체인 구성\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "system = \"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the user's question:\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 검색기 정의\n",
    "retriever = menu_db.as_retriever(\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# RAG 체인 실행\n",
    "query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# 답변 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 노드(Node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 수행 함수 정의\n",
    "def retrieve_and_respond(state: GraphState):\n",
    "    last_human_message = state['messages'][-1]\n",
    "    \n",
    "    # HumanMessage 객체의 content 속성에 접근\n",
    "    query = last_human_message.content\n",
    "    \n",
    "    # 문서 검색\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    # 응답 생성\n",
    "    response = rag_chain.invoke(query)\n",
    "    \n",
    "    # 검색된 문서와 응답을 상태에 저장\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"documents\": retrieved_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GradeResponse(BaseModel):\n",
    "    \"A score for answers\"\n",
    "    score: float = Field(..., ge=0, le=1, description=\"A score from 0 to 1, where 1 is perfect\")\n",
    "    explanation: str = Field(..., description=\"An explanation for the given score\")\n",
    "\n",
    "# 답변 품질 평가 함수\n",
    "def grade_answer(state: GraphState):\n",
    "    messages = state['messages']\n",
    "    question = messages[-2].content\n",
    "    answer = messages[-1].content\n",
    "    context = format_docs(state['documents'])\n",
    "\n",
    "    grading_system = \"\"\"You are an expert grader. \n",
    "    Grade the following answer based on its relevance and accuracy to the question, considering the given context. \n",
    "    Provide a score from 0 to 1, where 1 is perfect, along with an explanation.\"\"\"\n",
    "\n",
    "    grading_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", grading_system),\n",
    "        (\"human\", \"[Question]\\n{question}\\n\\n[Context]\\n{context}\\n\\n[Answer]\\n{answer}\\n\\n[Grade]\\n\")\n",
    "    ])\n",
    "    \n",
    "    grading_chain = grading_prompt | llm.with_structured_output(schema=GradeResponse)\n",
    "    \n",
    "    grade_response = grading_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "    # 답변 생성 횟수를 증가 \n",
    "    num_generation = state.get('num_generation', 0)\n",
    "    num_generation += 1\n",
    "    \n",
    "    return {\"grade\": grade_response.score, \"num_generation\": num_generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 엣지(Edge)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def should_retry(state: GraphState) -> Literal[\"retrieve_and_respond\", \"generate\"]:\n",
    "    print(\"----GRADTING---\")\n",
    "    print(\"Grade Score: \", state[\"grade\"])\n",
    "\n",
    "    # 답변 생성 횟수가 3회 이상이면 \"generate\"를 반환\n",
    "    if state[\"num_generation\"] > 2: \n",
    "        return \"generate\"    \n",
    "    \n",
    "    # 답변 품질 평가점수가 0.7 미만이면 RAG 체인을 다시 실행 \n",
    "    if state[\"grade\"] < 0.7:  \n",
    "        return \"retrieve_and_respond\"\n",
    "    else:\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 그래프(Graph) 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 설정\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"retrieve_and_respond\", retrieve_and_respond)\n",
    "builder.add_node(\"grade_answer\", grade_answer)\n",
    "\n",
    "builder.add_edge(START, \"retrieve_and_respond\")\n",
    "builder.add_edge(\"retrieve_and_respond\", \"grade_answer\")\n",
    "builder.add_conditional_edges(\n",
    "    \"grade_answer\",\n",
    "    should_retry,\n",
    "    {\n",
    "        \"retrieve_and_respond\": \"retrieve_and_respond\",\n",
    "        \"generate\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) Graph 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"채식주의자를 위한 메뉴를 추천해주세요.\")],\n",
    "}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\\n\")\n",
    "pprint(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변만 출력\n",
    "pprint(final_state['messages'][-1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 예시 질문들\n",
    "example_questions = [\n",
    "    \"채식주의자를 위한 메뉴를 추천해주세요.\",\n",
    "    \"오늘의 스페셜 메뉴는 무엇인가요?\",\n",
    "    \"파스타에 어울리는 음료는 무엇인가요?\"\n",
    "]\n",
    "\n",
    "# 대답 함수 정의\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "\n",
    "        # 기존 채팅 기록에 사용자의 메시지를 추가 (최근 2개 대화만 사용)\n",
    "        initial_state = {\n",
    "            \"messages\": chat_history[-2:]+[HumanMessage(content=message)],  \n",
    "        }\n",
    "\n",
    "        # 메시지를 처리하고 최종 상태를 반환\n",
    "        final_state = graph.invoke(initial_state)\n",
    "        \n",
    "        # 최종 상태에서 필요한 부분 반환 (예: 추천 메뉴 등)\n",
    "        return final_state[\"messages\"][-1].content\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Gradio 앱 실행\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
