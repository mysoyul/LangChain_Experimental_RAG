{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4394ecdf",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import uuid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a901480",
   "metadata": {},
   "source": [
    "###  2-1. Tool 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8f6d8",
   "metadata": {},
   "source": [
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"qwen2.5:1.5b\") \n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"./db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=6)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "\n",
    "# 레스토랑 와인 검색 \n",
    "wine_db = FAISS.load_local(\n",
    "    \"./db/wine_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "    Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = wine_db.similarity_search(query, k=6)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "\n",
    "# 웹 검색 \n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        formatted_docs.append(\n",
    "            Document(\n",
    "                page_content= f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>',\n",
    "                metadata={\"source\": \"web search\", \"url\": doc[\"url\"]}\n",
    "                )\n",
    "        )\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "\n",
    "# 도구 목록을 정의 \n",
    "tools = [search_menu, search_wine, search_web]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7f7a4",
   "metadata": {},
   "source": [
    "### 2-2. LLM 모델\n",
    "* bind_tools() 함수로 model 과 tool 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 기본 LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메뉴 검색에 관련된 질문을 하는 경우 -> 메뉴 검색 도구를 호출  \n",
    "query = \"대표 메뉴는 무엇인가요?\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689eddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구들의 목적과 관련 없는 질문을 하는 경우 -> 도구 호출 없이 그대로 답변을 생성 \n",
    "query = \"안녕하세요?\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 검색 목적과 관련된 질문을 하는 경우 -> 웹 검색 도구 호출 \n",
    "query = \"2024년 상반기 엔비디아 시가총액은 어떻게 변동했나요?\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa910b6",
   "metadata": {},
   "source": [
    "## 3. Adaptive RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb9f9c",
   "metadata": {},
   "source": [
    "### 3-1. 그래프 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53dacc5",
   "metadata": {},
   "source": [
    "`(1) 상태 정의`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be73335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 상태 Schema 정의 \n",
    "class AdaptiveRagState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd6f08",
   "metadata": {},
   "source": [
    "`(2) 질문 분석 -> 라우팅`\n",
    "- 사용자의 질문을 분석하여 적절한 검색 방법을 선택 \n",
    "- 레스토랑 메뉴 검색 or 레스토랑 와인 검색  or 일반 웹 검색 or 단순 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9830629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 라우팅 결정을 위한 데이터 모델\n",
    "class ToolSelector(BaseModel):\n",
    "    \"\"\"Routes the user question to the most appropriate tool.\"\"\"\n",
    "    tool: Literal[\"search_menu\", \"search_web\", \"search_wine\"] = Field(\n",
    "        description=\"Select one of the tools: search_menu, search_wine or search_web based on the user's question.\",\n",
    "    )\n",
    "\n",
    "# 구조화된 출력을 위한 LLM 설정\n",
    "structured_llm = llm.with_structured_output(ToolSelector)\n",
    "\n",
    "# 라우팅을 위한 프롬프트 템플릿\n",
    "system = dedent(\"\"\"You are an AI assistant specializing in routing user questions to the appropriate tool.\n",
    "Use the following guidelines:\n",
    "- For questions about the restaurant's menu, use the search_menu tool.\n",
    "- For wine recommendations or pairing information, use the search_wine tool.\n",
    "- For any other information or the most up-to-date data, use the search_web tool.\n",
    "Always choose the most appropriate tool based on the user's question.\"\"\")\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 질문 라우터 정의\n",
    "question_router = route_prompt | structured_llm\n",
    "\n",
    "# 테스트 실행\n",
    "print(question_router.invoke({\"question\": \"채식주의자를 위한 메뉴가 있나요?\"}))\n",
    "print(question_router.invoke({\"question\": \"스테이크 메뉴와 어울리는 와인을 추천해주세요.\"}))\n",
    "print(question_router.invoke({\"question\": \"2022년 월드컵 우승 국가는 어디인가요?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70feebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 라우팅 노드 \n",
    "def route_question_adaptive(state: AdaptiveRagState) -> Literal[\"search_menu\", \"search_wine\", \"search_web\", \"llm_fallback\"]:\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        result = question_router.invoke({\"question\": question})\n",
    "        datasource = result.tool\n",
    "        \n",
    "        if datasource == \"search_menu\":\n",
    "            return \"search_menu\"\n",
    "        elif datasource == \"search_wine\":\n",
    "            return \"search_wine\"        \n",
    "        elif datasource == \"search_web\":\n",
    "            return \"search_web\"\n",
    "        else:\n",
    "            return \"llm_fallback\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in routing: {str(e)}\")\n",
    "        return \"llm_fallback\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8b91a",
   "metadata": {},
   "source": [
    "`(3) 검색 노드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_menu_adaptive(state: AdaptiveRagState):\n",
    "    \"\"\"\n",
    "    Node for searching information in the restaurant menu\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    docs = search_menu.invoke(question)\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return {\"documents\": docs}\n",
    "    else:\n",
    "        return {\"documents\": [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]}\n",
    "\n",
    "\n",
    "def search_wine_adaptive(state: AdaptiveRagState):\n",
    "    \"\"\"\n",
    "    Node for searching information in the restaurant's wine list\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    docs = search_wine.invoke(question)\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return {\"documents\": docs}\n",
    "    else:\n",
    "        return {\"documents\": [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]}\n",
    "\n",
    "\n",
    "def search_web_adaptive(state: AdaptiveRagState):\n",
    "    \"\"\"\n",
    "    Node for searching the web for information not available in the restaurant menu \n",
    "    or for up-to-date information, and returning the results\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    docs = search_web.invoke(question)\n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        return {\"documents\": docs}\n",
    "    else:\n",
    "        return {\"documents\": [Document(page_content=\"관련 정보를 찾을 수 없습니다.\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19552a",
   "metadata": {},
   "source": [
    "`(4) 생성 노드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f70286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG 프롬프트 정의\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an assistant answering questions based on provided documents. Follow these guidelines:\n",
    "\n",
    "1. Use only information from the given documents.\n",
    "2. If the document lacks relevant info, say \"The provided documents don't contain information to answer this question.\"\n",
    "3. Cite relevant parts of the document in your answers.\n",
    "4. Don't speculate or add information not in the documents.\n",
    "5. Keep answers concise and clear.\n",
    "6. Omit irrelevant information.\"\"\"\n",
    "),\n",
    "    (\"human\", \"Answer the following question using these documents:\\n\\n[Documents]\\n{documents}\\n\\n[Question]\\n{question}\"),\n",
    "])\n",
    "\n",
    "def generate_adaptive(state: AdaptiveRagState):\n",
    "    \"\"\"\n",
    "    Generate answer using the retrieved_documents\n",
    "    \"\"\"\n",
    "    question = state.get(\"question\", None)\n",
    "    documents = state.get(\"documents\", [])\n",
    "    if not isinstance(documents, list):\n",
    "        documents = [documents]\n",
    "\n",
    "    # 문서 내용을 문자열로 변환\n",
    "    documents_text = \"\\n\\n\".join([f\"---\\n본문: {doc.page_content}\\n메타데이터:{str(doc.metadata)}\\n---\" for doc in documents])\n",
    "\n",
    "    # RAG generation\n",
    "    rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "    generation = rag_chain.invoke({\"documents\": documents_text, \"question\": question})\n",
    "    return {\"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7312a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Fallback 프롬프트 정의\n",
    "fallback_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI assistant helping with various topics. Follow these guidelines:\n",
    "\n",
    "1. Provide accurate and helpful information to the best of your ability.\n",
    "2. Express uncertainty when unsure; avoid speculation.\n",
    "3. Keep answers concise yet informative.\n",
    "4. Inform users they can ask for clarification if needed.\n",
    "5. Respond ethically and constructively.\n",
    "6. Mention reliable general sources when applicable.\"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "def llm_fallback_adaptive(state: AdaptiveRagState):\n",
    "    \"\"\"\n",
    "    Generate answer using the LLM without context\n",
    "    \"\"\"\n",
    "    question = state.get(\"question\", \"\")\n",
    "    \n",
    "    # LLM chain\n",
    "    llm_chain = fallback_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    generation = llm_chain.invoke({\"question\": question})\n",
    "    return {\"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388d9e3",
   "metadata": {},
   "source": [
    "`(5) 그래프 연결`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeabf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(AdaptiveRagState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"search_menu\", search_menu_adaptive)\n",
    "builder.add_node(\"search_wine\", search_wine_adaptive)\n",
    "builder.add_node(\"search_web\", search_web_adaptive)\n",
    "builder.add_node(\"generate\", generate_adaptive)\n",
    "builder.add_node(\"llm_fallback\", llm_fallback_adaptive)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_conditional_edges(\n",
    "    START,\n",
    "    route_question_adaptive\n",
    ")\n",
    "\n",
    "builder.add_edge(\"search_menu\", \"generate\")\n",
    "builder.add_edge(\"search_wine\", \"generate\")\n",
    "builder.add_edge(\"search_web\", \"generate\")\n",
    "builder.add_edge(\"generate\", END)\n",
    "builder.add_edge(\"llm_fallback\", END)\n",
    "\n",
    "# 그래프 컴파일 \n",
    "adaptive_rag = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(adaptive_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39203d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"question\": \"스테이크 메뉴의 가격은 얼마인가요?\"}\n",
    "for output in adaptive_rag.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Node '{key}':\")\n",
    "        print(f\"State '{value.keys()}':\")\n",
    "        print(f\"Value '{value}':\")\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# 최종 답변\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c15796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"question\": \"푸이 퓌세 2019의 주요 품종은 무엇인가요?\"}\n",
    "for output in adaptive_rag.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Node '{key}':\")\n",
    "        print(f\"State '{value.keys()}':\")\n",
    "        pprint(f\"Value '{value}':\")\n",
    "        #pprint(f\"Value '{value.page_content}':\")\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# 최종 답변\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67a568",
   "metadata": {},
   "source": [
    "### 3-2. 사람의 개입 (Human-in-the-Loop)\n",
    "\n",
    "- Human-in-the-Loop (HITL)는 AI 시스템에 인간의 판단과 개입을 통합하는 접근 방식\n",
    "- AI의 자동화된 처리와 인간의 전문성을 결합하여 더 정확하고 신뢰할 수 있는 결과를 도출하는 것을 목표\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f516a1f",
   "metadata": {},
   "source": [
    "`(1) 체크포인트 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced52a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06be5d",
   "metadata": {},
   "source": [
    "`(2) Breakpoint 추가`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5db53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일 - 'generate' 노드 전에 중단점 추가\n",
    "adaptive_rag_hitl = builder.compile(checkpointer=memory, interrupt_before=[\"generate\"])\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(adaptive_rag_hitl.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fbc90",
   "metadata": {},
   "source": [
    "`(3) Breakpoint 실행 확인`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a445aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 사용 전 중단점에서 실행을 멈춤 \n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"breakpoint_test\"}}\n",
    "inputs = {\"question\": \"스테이크 메뉴의 가격은 얼마인가요?\"}\n",
    "for event in adaptive_rag_hitl.stream(inputs, config=thread):\n",
    "    for k, v in event.items():\n",
    "        # '__end__' 이벤트는 미출력\n",
    "        if k != \"__end__\":\n",
    "            print(f\"{k}: {v}\")  # 이벤트의 키와 값을 함께 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a523e8",
   "metadata": {},
   "source": [
    "`(4) Breakpoint 상태 관리`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 확인\n",
    "current_state = adaptive_rag_hitl.get_state(thread)\n",
    "print(\"---그래프 상태---\")\n",
    "print(current_state)\n",
    "print(\"-\"*50)\n",
    "print(current_state.values.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07987daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음에 실행될 노드를 확인 \n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac16239",
   "metadata": {},
   "source": [
    "`(5) Breakpoint 이후 단계를 계속해서 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c14bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값을 None으로 지정하면 중단점부터 실행하는 의미 \n",
    "for event in adaptive_rag_hitl.stream(None, config=thread):\n",
    "    for k, v in event.items():\n",
    "        # '__end__' 이벤트는 미출력\n",
    "        if k != \"__end__\":\n",
    "            print(f\"{k}: {v}\")  # 이벤트의 키와 값을 함께 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음에 실행될 노드를 확인 \n",
    "current_state = adaptive_rag_hitl.get_state(thread)\n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e533e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변\n",
    "current_state = adaptive_rag_hitl.get_state(thread)\n",
    "print(current_state.values.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8964592",
   "metadata": {},
   "source": [
    "`(6) 상태 업데이트`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 thread를 생성하고, 새로운 질문을 수행 \n",
    "thread = {\"configurable\": {\"thread_id\": \"breakpoint_update\"}}\n",
    "inputs = {\"question\": \"매운 음식이 있나요?\"}\n",
    "for event in adaptive_rag_hitl.stream(inputs, config=thread):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(f\"{k}: {v}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee35fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음에 실행될 노드를 확인 \n",
    "current_state = adaptive_rag_hitl.get_state(thread)\n",
    "current_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af930c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question, generation 필드 확인\n",
    "current_state = adaptive_rag_hitl.get_state(thread)\n",
    "print(current_state.values.get(\"question\"))\n",
    "print(\"-\"*50)\n",
    "print(current_state.values.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 업데이트 - 질문을 수정하여 업데이트\n",
    "adaptive_rag_hitl.update_state(thread, {\"question\": \"매콤한 해산물 요리가 있나요?\"})\n",
    "\n",
    "# 상태 확인\n",
    "new_state = adaptive_rag_hitl.get_state(thread)\n",
    "\n",
    "print(new_state.values.get(\"question\"))\n",
    "print(\"-\"*50)\n",
    "print(new_state.values.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb057b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값을 None으로 지정하면 중단점부터 실행하고 최종 답변을 생성 \n",
    "for event in adaptive_rag_hitl.stream(None, config=thread):\n",
    "    for k, v in event.items():\n",
    "        # '__end__' 이벤트는 미출력\n",
    "        if k != \"__end__\":\n",
    "            print(f\"{k}: {v}\")  # 이벤트의 키와 값을 함께 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변 확인\n",
    "print(event[\"generate\"][\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
